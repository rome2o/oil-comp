{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebef0a92",
   "metadata": {},
   "source": [
    "# HBNO Shopify Plus Growth Service\n",
    "## Phase 1: Data Foundation & Current State Analysis\n",
    "\n",
    "**Objective**: Load, clean, and analyze all available Shopify data to establish current baseline metrics and identify key performance indicators.\n",
    "\n",
    "**Data Sources**:\n",
    "- Shopify reports (14 CSV files with 12-month historical data)\n",
    "- Analysis outputs (JSON files with competitive and opportunity data)\n",
    "- Existing reports (markdown insights)\n",
    "\n",
    "**Key Outputs**: Unified dataset with baseline metrics for proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce371b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries loaded successfully\n",
      "üìÖ Analysis Date: November 14, 2025 at 12:59 AM\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully\")\n",
    "print(f\"üìÖ Analysis Date: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa534325",
   "metadata": {},
   "source": [
    "### 1. Load and Explore Shopify Data\n",
    "\n",
    "Loading all 14 Shopify report CSV files from the shopify-reports folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c24e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading Shopify Reports from: /Users/ali/Sites/business/oil-company/project-techteam/shopify-reports/\n",
      "Found 14 CSV files\n",
      "\n",
      "‚úÖ Average order value over time - 2024-11-13 - 2025-11-13\n",
      "   Shape: (13, 14) | Columns: ['Month', 'Gross sales', 'Discounts']...\n",
      "\n",
      "‚úÖ Bounce rate over time - 2024-11-13 - 2025-11-13\n",
      "   Shape: (13, 5) | Columns: ['Month', 'Bounce rate', 'Month (previous_period)']...\n",
      "\n",
      "‚úÖ Checkout conversion rate over time - 2024-11-13 - 2025-11-13\n",
      "   Shape: (13, 11) | Columns: ['Month', 'Sessions that reached checkout', 'Sessions that completed checkout']...\n",
      "\n",
      "‚úÖ Conversion rate breakdown - 2025-08-15 - 2025-11-13\n",
      "   Shape: (91, 17) | Columns: ['Day', 'Sessions', 'Sessions with cart additions']...\n",
      "\n",
      "‚úÖ Customer behavior - 2024-11-13 - 2025-11-13\n",
      "   Shape: (1, 3) | Columns: ['Sessions with cart additions', 'Sessions that reached checkout', 'Sessions that completed checkout']...\n",
      "\n",
      "‚úÖ New customer sales over time - 2024-11-13 - 2025-11-13\n",
      "   Shape: (13, 12) | Columns: ['New or returning customer', 'Month', 'Customers']...\n",
      "\n",
      "‚úÖ New customers over time - 2024-11-13 - 2025-11-13\n",
      "   Shape: (13, 11) | Columns: ['Month', 'Customers', 'Orders']...\n",
      "\n",
      "‚úÖ New vs returning customer sales - 2024-11-13 - 2025-11-13\n",
      "   Shape: (26, 12) | Columns: ['New or returning customer', 'Month', 'Customers']...\n",
      "\n",
      "‚úÖ New vs returning customers - 2024-11-13 - 2025-11-13\n",
      "   Shape: (2, 4) | Columns: ['New or returning customer', 'Customers', 'Customers (previous_period)']...\n",
      "\n",
      "‚úÖ Returning customer rate over time - 2024-11-13 - 2025-11-13\n",
      "   Shape: (13, 11) | Columns: ['Month', 'Returning customers', 'Customers']...\n",
      "\n",
      "‚úÖ Sales attributed to marketing - 2024-11-13 - 2025-11-13\n",
      "   Shape: (41, 14) | Columns: ['Referring channel', 'Referring medium', 'Orders']...\n",
      "\n",
      "‚úÖ Sessions by location - 2024-11-13 - 2025-11-13\n",
      "   Shape: (13705, 5) | Columns: ['Session country', 'Session region', 'Session city']...\n",
      "\n",
      "‚úÖ Sessions by referrer - 2024-11-13 - 2025-11-13\n",
      "   Shape: (478, 4) | Columns: ['Referrer source', 'Referrer name', 'Online store visitors']...\n",
      "\n",
      "‚úÖ Total sales by product - 2024-11-13 - 2025-11-13\n",
      "   Shape: (537, 10) | Columns: ['Product title', 'Product vendor', 'Product type']...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "shopify_reports_path = \"/Users/ali/Sites/business/oil-company/project-techteam/shopify-reports/\"\n",
    "analysis_outputs_path = \"/Users/ali/Sites/business/oil-company/hbno_analysis_outputs/\"\n",
    "reports_path = \"/Users/ali/Sites/business/oil-company/reports/\"\n",
    "\n",
    "# Load all Shopify CSV files\n",
    "shopify_files = glob.glob(os.path.join(shopify_reports_path, \"*.csv\"))\n",
    "shopify_data = {}\n",
    "\n",
    "print(f\"üìÅ Loading Shopify Reports from: {shopify_reports_path}\")\n",
    "print(f\"Found {len(shopify_files)} CSV files\\n\")\n",
    "\n",
    "for file in sorted(shopify_files):\n",
    "    filename = os.path.basename(file)\n",
    "    df = pd.read_csv(file)\n",
    "    # Use filename without extension as key\n",
    "    key = filename.replace(\".csv\", \"\")\n",
    "    shopify_data[key] = df\n",
    "    print(f\"‚úÖ {key}\")\n",
    "    print(f\"   Shape: {df.shape} | Columns: {list(df.columns[:3])}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6cf5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading Analysis Outputs from: /Users/ali/Sites/business/oil-company/hbno_analysis_outputs/\n",
      "\n",
      "‚úÖ hbno_analysis_report.json\n",
      "‚úÖ hbno_comprehensive_analysis_report.json\n",
      "‚úÖ hbno_enhanced_comprehensive_analysis.json\n",
      "‚úÖ hbno_ultimate_comprehensive_analysis_fast.json\n",
      "‚úÖ seo_opportunities_analysis.json\n",
      "‚úÖ shopify_data_summary.json\n",
      "‚úÖ ultimate_shopify_data_summary.json\n",
      "\n",
      "üìÑ Found 4 CSV files in analysis outputs\n",
      "   - hbno_enhanced_service_proposals.csv\n",
      "   - hbno_service_proposals.csv\n",
      "   - hbno_ultimate_service_proposals.csv\n",
      "   - hbno_ultimate_service_proposals_optimized.csv\n"
     ]
    }
   ],
   "source": [
    "# Load analysis outputs\n",
    "print(f\"üìä Loading Analysis Outputs from: {analysis_outputs_path}\\n\")\n",
    "\n",
    "analysis_outputs = {}\n",
    "json_files = glob.glob(os.path.join(analysis_outputs_path, \"*.json\"))\n",
    "\n",
    "for file in sorted(json_files):\n",
    "    filename = os.path.basename(file)\n",
    "    try:\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            key = filename.replace(\".json\", \"\")\n",
    "            analysis_outputs[key] = data\n",
    "            print(f\"‚úÖ {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error loading {filename}: {str(e)}\")\n",
    "\n",
    "# Also check for CSV outputs\n",
    "csv_outputs = glob.glob(os.path.join(analysis_outputs_path, \"*.csv\"))\n",
    "print(f\"\\nüìÑ Found {len(csv_outputs)} CSV files in analysis outputs\")\n",
    "for file in sorted(csv_outputs):\n",
    "    filename = os.path.basename(file)\n",
    "    print(f\"   - {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72578b87",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning & Preparation\n",
    "\n",
    "Standardize data formats and prepare datasets for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9841a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleaning Shopify datasets...\n",
      "\n",
      "‚úÖ Average order value over time - 2024-11-13 - 2025-11-13: 13 rows after cleaning\n",
      "‚úÖ Bounce rate over time - 2024-11-13 - 2025-11-13: 13 rows after cleaning\n",
      "‚úÖ Checkout conversion rate over time - 2024-11-13 - 2025-11-13: 13 rows after cleaning\n",
      "‚úÖ Conversion rate breakdown - 2025-08-15 - 2025-11-13: 91 rows after cleaning\n",
      "‚úÖ Customer behavior - 2024-11-13 - 2025-11-13: 1 rows after cleaning\n",
      "‚úÖ New customer sales over time - 2024-11-13 - 2025-11-13: 13 rows after cleaning\n",
      "‚úÖ New customers over time - 2024-11-13 - 2025-11-13: 13 rows after cleaning\n",
      "‚úÖ New vs returning customer sales - 2024-11-13 - 2025-11-13: 26 rows after cleaning\n",
      "‚úÖ New vs returning customers - 2024-11-13 - 2025-11-13: 2 rows after cleaning\n",
      "‚úÖ Returning customer rate over time - 2024-11-13 - 2025-11-13: 13 rows after cleaning\n",
      "‚úÖ Sales attributed to marketing - 2024-11-13 - 2025-11-13: 41 rows after cleaning\n",
      "‚úÖ Sessions by location - 2024-11-13 - 2025-11-13: 13705 rows after cleaning\n",
      "‚úÖ Sessions by referrer - 2024-11-13 - 2025-11-13: 478 rows after cleaning\n",
      "‚úÖ Total sales by product - 2024-11-13 - 2025-11-13: 537 rows after cleaning\n",
      "\n",
      "üìä Datasets ready: ['Average order value over time - 2024-11-13 - 2025-11-13', 'Bounce rate over time - 2024-11-13 - 2025-11-13', 'Checkout conversion rate over time - 2024-11-13 - 2025-11-13', 'Conversion rate breakdown - 2025-08-15 - 2025-11-13', 'Customer behavior - 2024-11-13 - 2025-11-13', 'New customer sales over time - 2024-11-13 - 2025-11-13', 'New customers over time - 2024-11-13 - 2025-11-13', 'New vs returning customer sales - 2024-11-13 - 2025-11-13', 'New vs returning customers - 2024-11-13 - 2025-11-13', 'Returning customer rate over time - 2024-11-13 - 2025-11-13', 'Sales attributed to marketing - 2024-11-13 - 2025-11-13', 'Sessions by location - 2024-11-13 - 2025-11-13', 'Sessions by referrer - 2024-11-13 - 2025-11-13', 'Total sales by product - 2024-11-13 - 2025-11-13']\n"
     ]
    }
   ],
   "source": [
    "# Function to standardize date columns\n",
    "def parse_date_flexible(date_str):\n",
    "    \"\"\"Try multiple date formats\"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    formats = ['%Y-%m-%d', '%m/%d/%Y', '%d-%m-%Y', '%B %d, %Y']\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt)\n",
    "        except:\n",
    "            continue\n",
    "    return pd.to_datetime(date_str, errors='coerce')\n",
    "\n",
    "# Clean Shopify data\n",
    "print(\"üßπ Cleaning Shopify datasets...\\n\")\n",
    "\n",
    "cleaned_data = {}\n",
    "for key, df in shopify_data.items():\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Try to find and parse date columns\n",
    "    for col in df_clean.columns:\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\n",
    "            df_clean[col] = df_clean[col].apply(parse_date_flexible)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    \n",
    "    # Store cleaned version\n",
    "    cleaned_data[key] = df_clean\n",
    "    print(f\"‚úÖ {key}: {df_clean.shape[0]} rows after cleaning\")\n",
    "\n",
    "print(f\"\\nüìä Datasets ready: {list(cleaned_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905cdf9d",
   "metadata": {},
   "source": [
    "### 3. Establish Baseline Metrics\n",
    "\n",
    "Extract key performance indicators from available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3e4ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Average Order Value: $92587.75\n",
      "üìä Average Conversion Rate: 40261.54%\n",
      "üîÑ Average Bounce Rate: 77.08%\n",
      "\n",
      "üë• Customer Segmentation:\n",
      "  New or returning customer  Customers  Customers (previous_period)  \\\n",
      "0                       New        763                          781   \n",
      "1                 Returning        736                          745   \n",
      "\n",
      "   Customers (previous_period)   \n",
      "0                     -1.801802  \n",
      "1                     -0.808625  \n",
      "\n",
      "‚úÖ Baseline metrics established: 3 KPIs\n"
     ]
    }
   ],
   "source": [
    "# Extract baseline metrics\n",
    "baseline_metrics = {}\n",
    "\n",
    "# Average Order Value\n",
    "if 'Average order value over time - 2024-11-13 - 2025-11-13' in cleaned_data:\n",
    "    aov_df = cleaned_data['Average order value over time - 2024-11-13 - 2025-11-13']\n",
    "    if not aov_df.empty:\n",
    "        # Look for numeric columns\n",
    "        numeric_cols = aov_df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            avg_aov = aov_df[numeric_cols[0]].mean()\n",
    "            baseline_metrics['avg_order_value'] = float(avg_aov)\n",
    "            print(f\"üí∞ Average Order Value: ${avg_aov:.2f}\")\n",
    "\n",
    "# Conversion Rate\n",
    "if 'Checkout conversion rate over time - 2024-11-13 - 2025-11-13' in cleaned_data:\n",
    "    conv_df = cleaned_data['Checkout conversion rate over time - 2024-11-13 - 2025-11-13']\n",
    "    if not conv_df.empty:\n",
    "        numeric_cols = conv_df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            avg_conv = conv_df[numeric_cols[0]].mean()\n",
    "            baseline_metrics['avg_conversion_rate'] = float(avg_conv)\n",
    "            print(f\"üìä Average Conversion Rate: {avg_conv:.2%}\")\n",
    "\n",
    "# Bounce Rate\n",
    "if 'Bounce rate over time - 2024-11-13 - 2025-11-13' in cleaned_data:\n",
    "    bounce_df = cleaned_data['Bounce rate over time - 2024-11-13 - 2025-11-13']\n",
    "    if not bounce_df.empty:\n",
    "        numeric_cols = bounce_df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            avg_bounce = bounce_df[numeric_cols[0]].mean()\n",
    "            baseline_metrics['avg_bounce_rate'] = float(avg_bounce)\n",
    "            print(f\"üîÑ Average Bounce Rate: {avg_bounce:.2%}\")\n",
    "\n",
    "# New vs Returning Customers\n",
    "if 'New vs returning customers - 2024-11-13 - 2025-11-13' in cleaned_data:\n",
    "    customer_df = cleaned_data['New vs returning customers - 2024-11-13 - 2025-11-13']\n",
    "    if not customer_df.empty:\n",
    "        print(f\"\\nüë• Customer Segmentation:\")\n",
    "        print(customer_df.head())\n",
    "\n",
    "print(f\"\\n‚úÖ Baseline metrics established: {len(baseline_metrics)} KPIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b543e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Top Performing Products:\n",
      "                       Product title Product vendor   Product type  \\\n",
      "0       Lavender 40/42 Essential Oil       HBNO inc          Blend   \n",
      "1           Peppermint Essential Oil       HBNO inc  essential oil   \n",
      "2             Rosemary Essential Oil       HBNO inc  essential oil   \n",
      "3        Cinnamon Bark Essential Oil       HBNO inc  Essential Oil   \n",
      "4           Lemongrass Essential Oil       HBNO inc  Essential Oil   \n",
      "5  Eucalyptus Globulus Essential Oil       HBNO inc  Essential Oil   \n",
      "6                 Neossance Squalane       HBNO inc  essential oil   \n",
      "7             Tea Tree Essential Oil       HBNO inc  essential oil   \n",
      "8         Frankincense Oil (Serrata)       HBNO inc  essential oil   \n",
      "9   Peppermint Essential Oil Organic       HBNO inc  essential oil   \n",
      "\n",
      "   Net items sold  Gross sales  Discounts  Returns  Net sales    Taxes  \\\n",
      "0             435     71573.29    -438.93    -5.40   71128.96  1620.73   \n",
      "1             321     68366.09    -244.44  -934.50   67187.15  1387.85   \n",
      "2             251     53201.98    -412.16     0.00   52789.82  1511.36   \n",
      "3              51     39619.03    -325.56  -995.00   38298.47    41.85   \n",
      "4             282     33215.38    -300.56  -597.50   32317.32   828.68   \n",
      "5             239     31522.45    -344.64  -499.00   30678.81   619.74   \n",
      "6              67     31209.42    -516.47  -648.00   30044.95  1014.60   \n",
      "7             191     29521.61    -191.21    -9.99   29320.41   467.48   \n",
      "8             113     28121.80     -76.78     0.00   28045.02   316.37   \n",
      "9             117     24146.95    -636.85   -20.00   23490.10   245.79   \n",
      "\n",
      "   Total sales  \n",
      "0     72749.69  \n",
      "1     68575.00  \n",
      "2     54301.18  \n",
      "3     38340.32  \n",
      "4     33146.00  \n",
      "5     31298.55  \n",
      "6     31059.55  \n",
      "7     29787.89  \n",
      "8     28361.39  \n",
      "9     23735.89  \n",
      "\n",
      "üíπ Total 12-Month Revenue: $10,345.00\n",
      "üìà Average Monthly Revenue: $862.08\n",
      "\n",
      "üåç Top Geographic Markets:\n",
      "  Session country Session region    Session city  Online store visitors  \\\n",
      "0   United States       Virginia         Ashburn                  31820   \n",
      "1   United States           Iowa  Council Bluffs                  12093   \n",
      "2   United States            NaN             NaN                   7268   \n",
      "3       Singapore            NaN       Singapore                   6139   \n",
      "4   United States     California     Los Angeles                   2302   \n",
      "5         Germany            NaN             NaN                   3672   \n",
      "6       Hong Kong            NaN       Hong Kong                   3595   \n",
      "7   United States     California           Chico                    353   \n",
      "8        Pakistan          Sindh         Karachi                    735   \n",
      "9          Mexico    Mexico City     Mexico City                   1833   \n",
      "\n",
      "   Sessions  \n",
      "0     31849  \n",
      "1     12096  \n",
      "2      7508  \n",
      "3      6269  \n",
      "4      3787  \n",
      "5      3673  \n",
      "6      3617  \n",
      "7      3464  \n",
      "8      2456  \n",
      "9      1844  \n",
      "\n",
      "üîó Top Traffic Sources:\n",
      "  Referrer source Referrer name  Online store visitors  Sessions\n",
      "0          direct           NaN                 111423    140554\n",
      "1          search        google                  78491     92386\n",
      "2          search    duckduckgo                   3884      4461\n",
      "3          search          bing                   2694      3127\n",
      "4          social      facebook                   1443      1470\n",
      "5          search        yahoo!                   1112      1313\n",
      "6         unknown       chatgpt                   1007      1116\n",
      "7         unknown         brave                    712       820\n",
      "8         unknown       shopify                    509       729\n",
      "9          search        yandex                    670       676\n"
     ]
    }
   ],
   "source": [
    "# Extract detailed metrics from Total Sales by Product\n",
    "if 'Total sales by product - 2024-11-13 - 2025-11-13' in cleaned_data:\n",
    "    sales_df = cleaned_data['Total sales by product - 2024-11-13 - 2025-11-13']\n",
    "    print(\"üèÜ Top Performing Products:\")\n",
    "    print(sales_df.head(10))\n",
    "    \n",
    "    # Try to extract total revenue\n",
    "    numeric_cols = sales_df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        total_revenue = sales_df[numeric_cols[0]].sum()\n",
    "        baseline_metrics['total_revenue'] = float(total_revenue)\n",
    "        baseline_metrics['avg_monthly_revenue'] = float(total_revenue / 12)\n",
    "        print(f\"\\nüíπ Total 12-Month Revenue: ${total_revenue:,.2f}\")\n",
    "        print(f\"üìà Average Monthly Revenue: ${total_revenue/12:,.2f}\")\n",
    "\n",
    "# Extract sessions data\n",
    "if 'Sessions by location - 2024-11-13 - 2025-11-13' in cleaned_data:\n",
    "    location_df = cleaned_data['Sessions by location - 2024-11-13 - 2025-11-13']\n",
    "    print(\"\\nüåç Top Geographic Markets:\")\n",
    "    print(location_df.head(10))\n",
    "\n",
    "if 'Sessions by referrer - 2024-11-13 - 2025-11-13' in cleaned_data:\n",
    "    referrer_df = cleaned_data['Sessions by referrer - 2024-11-13 - 2025-11-13']\n",
    "    print(\"\\nüîó Top Traffic Sources:\")\n",
    "    print(referrer_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f65e5f",
   "metadata": {},
   "source": [
    "### 4. Load Analysis Insights\n",
    "\n",
    "Incorporate existing analysis and opportunity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d13cb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Analysis Outputs Summary:\n",
      "\n",
      "‚úÖ Loaded comprehensive analysis\n",
      "\n",
      "üìä Shopify Data Summary loaded\n",
      "Keys: ['checkout_conversion_rate_over_time', 'total_sales_by_product', 'sessions_by_referrer', 'conversion_rate_breakdown', 'bounce_rate_over_time', 'customer_behavior', 'sales_attributed_to_marketing', 'sessions_by_location', 'average_order_value_over_time', 'new_vs_returning_customer_sales']\n",
      "\n",
      "üöÄ Opportunity Analysis loaded\n",
      "Keys: ['detailed_analysis']\n",
      "\n",
      "‚úÖ Analysis insights integrated\n"
     ]
    }
   ],
   "source": [
    "# Load and display analysis insights\n",
    "print(\"üìã Analysis Outputs Summary:\\n\")\n",
    "\n",
    "if 'hbno_ultimate_comprehensive_analysis_fast' in analysis_outputs:\n",
    "    analysis = analysis_outputs['hbno_ultimate_comprehensive_analysis_fast']\n",
    "    print(\"‚úÖ Loaded comprehensive analysis\")\n",
    "    \n",
    "    # Extract key insights if available\n",
    "    if 'executive_summary' in analysis:\n",
    "        print(\"\\nüéØ Executive Summary:\")\n",
    "        print(analysis['executive_summary'][:500])\n",
    "\n",
    "if 'ultimate_shopify_data_summary' in analysis_outputs:\n",
    "    shopify_summary = analysis_outputs['ultimate_shopify_data_summary']\n",
    "    print(\"\\nüìä Shopify Data Summary loaded\")\n",
    "    \n",
    "    # Display structure\n",
    "    if isinstance(shopify_summary, dict):\n",
    "        print(f\"Keys: {list(shopify_summary.keys())[:10]}\")\n",
    "\n",
    "# Load opportunity analysis\n",
    "if 'seo_opportunities_analysis' in analysis_outputs:\n",
    "    opportunities = analysis_outputs['seo_opportunities_analysis']\n",
    "    print(\"\\nüöÄ Opportunity Analysis loaded\")\n",
    "    if isinstance(opportunities, dict):\n",
    "        print(f\"Keys: {list(opportunities.keys())[:10]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis insights integrated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85841497",
   "metadata": {},
   "source": [
    "### 5. Create Baseline Summary Report\n",
    "\n",
    "Compile key baseline metrics for proposal foundation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e653ffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä HBNO BASELINE METRICS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Analysis Period: November 13, 2024 - November 13, 2025 (12 months)\n",
      "Data Collection Date: November 14, 2025 at 12:59 AM\n",
      "\n",
      "üí∞ REVENUE METRICS:\n",
      "----------------------------------------\n",
      "  Total Revenue: $10,345.00\n",
      "  Avg Monthly Revenue: $862.08\n",
      "\n",
      "üìà PERFORMANCE METRICS:\n",
      "----------------------------------------\n",
      "  Avg Order Value: $92587.75\n",
      "  Avg Conversion Rate: 40261.54%\n",
      "  Avg Bounce Rate: 77.08%\n",
      "\n",
      "üìÅ DATA SOURCES LOADED:\n",
      "----------------------------------------\n",
      "  Shopify Reports: 14 datasets\n",
      "  Analysis Outputs: 7 analysis files\n",
      "  Total Metrics Extracted: 5 KPIs\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive baseline metrics summary\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä HBNO BASELINE METRICS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nAnalysis Period: November 13, 2024 - November 13, 2025 (12 months)\")\n",
    "print(f\"Data Collection Date: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}\")\n",
    "\n",
    "print(\"\\nüí∞ REVENUE METRICS:\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in baseline_metrics.items():\n",
    "    if 'revenue' in key.lower():\n",
    "        print(f\"  {key.replace('_', ' ').title()}: ${value:,.2f}\")\n",
    "\n",
    "print(\"\\nüìà PERFORMANCE METRICS:\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in baseline_metrics.items():\n",
    "    if 'rate' in key.lower():\n",
    "        print(f\"  {key.replace('_', ' ').title()}: {value:.2%}\")\n",
    "    elif 'order' in key.lower():\n",
    "        print(f\"  {key.replace('_', ' ').title()}: ${value:.2f}\")\n",
    "\n",
    "print(\"\\nüìÅ DATA SOURCES LOADED:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  Shopify Reports: {len(cleaned_data)} datasets\")\n",
    "print(f\"  Analysis Outputs: {len(analysis_outputs)} analysis files\")\n",
    "print(f\"  Total Metrics Extracted: {len(baseline_metrics)} KPIs\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5e1fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Baseline metrics saved to: /Users/ali/Sites/business/oil-company/project-techteam/shopify-plus-growth/output/baseline_metrics.json\n",
      "‚úÖ Data summary saved to: /Users/ali/Sites/business/oil-company/project-techteam/shopify-plus-growth/output/data_summary.json\n",
      "\n",
      "## PHASE 1 COMPLETION SUMMARY\n",
      "\n",
      "**Data Successfully Loaded:**\n",
      "- ‚úÖ Shopify Reports: 14 datasets\n",
      "- ‚úÖ Analysis Outputs: 7 files  \n",
      "- ‚úÖ Baseline Metrics: 5 KPIs\n",
      "\n",
      "**Ready for Next Phase:**\n",
      "All baseline metrics and data have been extracted and saved.\n",
      "Proceeding to Phase 2: Opportunity Analysis.\n",
      "\n",
      "**Next Notebook:** 02_opportunity_analysis.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save baseline metrics for downstream notebooks\n",
    "output_path = \"/Users/ali/Sites/business/oil-company/project-techteam/shopify-plus-growth/output/\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Save baseline metrics as JSON\n",
    "baseline_file = os.path.join(output_path, \"baseline_metrics.json\")\n",
    "with open(baseline_file, 'w') as f:\n",
    "    json.dump(baseline_metrics, f, indent=2, default=str)\n",
    "\n",
    "print(f\"‚úÖ Baseline metrics saved to: {baseline_file}\")\n",
    "\n",
    "# Save cleaned data references\n",
    "data_summary = {\n",
    "    'datasets_loaded': len(cleaned_data),\n",
    "    'dataset_names': list(cleaned_data.keys()),\n",
    "    'analysis_outputs_loaded': len(analysis_outputs),\n",
    "    'total_kpis_extracted': len(baseline_metrics)\n",
    "}\n",
    "\n",
    "data_summary_file = os.path.join(output_path, \"data_summary.json\")\n",
    "with open(data_summary_file, 'w') as f:\n",
    "    json.dump(data_summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"‚úÖ Data summary saved to: {data_summary_file}\")\n",
    "\n",
    "# Create a summary for display\n",
    "summary_text = f\"\"\"\n",
    "## PHASE 1 COMPLETION SUMMARY\n",
    "\n",
    "**Data Successfully Loaded:**\n",
    "- ‚úÖ Shopify Reports: {len(cleaned_data)} datasets\n",
    "- ‚úÖ Analysis Outputs: {len(analysis_outputs)} files  \n",
    "- ‚úÖ Baseline Metrics: {len(baseline_metrics)} KPIs\n",
    "\n",
    "**Ready for Next Phase:**\n",
    "All baseline metrics and data have been extracted and saved.\n",
    "Proceeding to Phase 2: Opportunity Analysis.\n",
    "\n",
    "**Next Notebook:** 02_opportunity_analysis.ipynb\n",
    "\"\"\"\n",
    "\n",
    "print(summary_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
